{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model using TFMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Evaluate input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval_receiver_fn(transform_artefacts_dir):\n",
    "    \n",
    "    transformed_metadata = metadata_io.read_metadata(transform_artefacts_dir+\"/transformed_metadata\")\n",
    "    transformed_feature_spec = transformed_metadata.schema.as_feature_spec()\n",
    "    \n",
    "    def _eval_receiver_fn():\n",
    "        \n",
    "        serialized_tf_example = tf.placeholder(\n",
    "            dtype=tf.string, shape=[None], name='input_example_placeholder')\n",
    "\n",
    "        receiver_tensors = {'examples': serialized_tf_example}\n",
    "        transformed_features = tf.parse_example(serialized_tf_example, transformed_feature_spec)\n",
    "\n",
    "        return tfma.export.EvalInputReceiver(\n",
    "            features=transformed_features,\n",
    "            receiver_tensors=receiver_tensors,\n",
    "            labels=transformed_features[TARGET_FEATURE_NAME])\n",
    "\n",
    "    return _eval_receiver_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Export Evaluation Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model_dir = model_dir +\"/export/evaluate\"\n",
    "\n",
    "transform_artefacts_dir = os.path.join(local_models_dir,TRANSFORM_ARTEFACTS_DIR)\n",
    "\n",
    "tfma.export.export_eval_savedmodel(\n",
    "        estimator=dnn_estimator,\n",
    "        export_dir_base=eval_model_dir,\n",
    "        eval_input_receiver_fn=generate_eval_receiver_fn(transform_artefacts_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Produce Evaluation Results using the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_spec = [tfma.SingleSliceSpec()]\n",
    "for feature_name, feature_spec in transformed_feature_spec.items():\n",
    "    if feature_name not in [KEY_COLUMN] + [TARGET_FEATURE_NAME] and feature_spec.dtype == tf.string:\n",
    "        slice_spec += [tfma.SingleSliceSpec(columns=[feature_name])]\n",
    "\n",
    "print slice_spec\n",
    "print \"\"\n",
    "\n",
    "saved_model_base_dir=os.path.join(model_dir,'export/evaluate')\n",
    "model_location=os.path.join(saved_model_base_dir, os.listdir(saved_model_base_dir)[0])\n",
    "data_location = os.path.join(local_data_dir, TRANSFORMED_DATA_DIR)+\"/eval-*.tfrecords\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "eval_results = tfma.run_model_analysis(\n",
    "    model_location=model_location , \n",
    "    data_location=data_location, \n",
    "    file_format='tfrecords', \n",
    "    slice_spec=slice_spec, \n",
    "#     output_path=None\n",
    ")\n",
    "\n",
    "print \"Evaluation results are ready!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualise the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print eval_results.slicing_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfma.view.render_slicing_metrics(\n",
    "        eval_results, \n",
    "    slicing_column='mother_race'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model on Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Submitting a Cloud ML Engine job...\"\n",
    "\n",
    "REGION=europe-west1\n",
    "TIER=BASIC # BASIC | BASIC_GPU | STANDARD_1 | PREMIUM_1\n",
    "BUCKET=ksalama-gcs-cloudml\n",
    "\n",
    "MODEL_NAME=\"babyweight_estimator\"\n",
    "\n",
    "PACKAGE_PATH=packages/babyweight-tf1.4/trainer\n",
    "TRAIN_FILES=gs://${BUCKET}/data/babyweight/train-data.csv\n",
    "VALID_FILES=gs://${BUCKET}/data/babyweight/eval-data.csv\n",
    "MODEL_DIR=gs://${BUCKET}/models/babyweight/${MODEL_NAME}\n",
    "\n",
    "#remove model directory, if you don't want to resume training, or if you have changed the model structure\n",
    "#gsutil -m rm -r ${MODEL_DIR}\n",
    "\n",
    "CURRENT_DATE=`date +%Y%m%d_%H%M%S`\n",
    "JOB_NAME=train_${MODEL_NAME}_${TIER}_${CURRENT_DATE}\n",
    "\n",
    "gcloud ml-engine jobs submit training ${JOB_NAME} \\\n",
    "        --job-dir=${MODEL_DIR} \\\n",
    "        --runtime-version=1.4 \\\n",
    "        --region=${REGION} \\\n",
    "        --scale-tier=${TIER} \\\n",
    "        --module-name=trainer.task \\\n",
    "        --package-path=${PACKAGE_PATH} \\\n",
    "        -- \\\n",
    "        --train-files=${TRAIN_FILES} \\\n",
    "        --num-epochs=100 \\\n",
    "        --train-batch-size=500 \\\n",
    "        --eval-files=${VALID_FILES} \\\n",
    "        --eval-batch-size=500 \\\n",
    "        --learning-rate=0.01 \\\n",
    "        --hidden-units=\"64,0,0\" \\\n",
    "        --layer-sizes-scale-factor=0.5 \\\n",
    "        --num-layers=3 \\\n",
    "        --job-dir=${MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model on Cloud ML Engine + GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Submitting a Cloud ML Engine job...\"\n",
    "\n",
    "REGION=europe-west1\n",
    "TIER=BASIC_GPU # BASIC | BASIC_GPU | STANDARD_1 | PREMIUM_1\n",
    "BUCKET=ksalama-gcs-cloudml\n",
    "\n",
    "MODEL_NAME=\"babyweight_estimator\"\n",
    "\n",
    "PACKAGE_PATH=packages/babyweight-tf1.4/trainer\n",
    "TRAIN_FILES=gs://${BUCKET}/data/babyweight/train-*.csv\n",
    "VALID_FILES=gs://${BUCKET}/data/babyweight/eval-*.csv\n",
    "MODEL_DIR=gs://${BUCKET}/models/babyweight/${MODEL_NAME}_${TIER}\n",
    "\n",
    "CURRENT_DATE=`date +%Y%m%d_%H%M%S`\n",
    "JOB_NAME=train_${MODEL_NAME}_${TIER}_${CURRENT_DATE}\n",
    "\n",
    "gcloud ml-engine jobs submit training ${JOB_NAME} \\\n",
    "        --job-dir=${MODEL_DIR} \\\n",
    "        --runtime-version=1.4 \\\n",
    "        --region=${REGION} \\\n",
    "        --scale-tier=${TIER} \\\n",
    "        --module-name=trainer.task \\\n",
    "        --package-path=${PACKAGE_PATH} \\\n",
    "        -- \\\n",
    "        --train-files=${TRAIN_FILES} \\\n",
    "        --num-epochs=10 \\\n",
    "        --train-batch-size=1000 \\\n",
    "        --eval-files=${VALID_FILES} \\\n",
    "        --eval-batch-size=1000 \\\n",
    "        --learning-rate=0.01 \\\n",
    "        --hidden-units=\"64,0,0\" \\\n",
    "        --layer-sizes-scale-factor=0.5 \\\n",
    "        --num-layers=3 \\\n",
    "        --job-dir=${MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model on Cloud ML Engine + Custom GPUs Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Submitting a Cloud ML Engine job...\"\n",
    "\n",
    "REGION=europe-west1\n",
    "TIER=CUSTOM # BASIC | BASIC_GPU | STANDARD_1 | PREMIUM_1\n",
    "BUCKET=ksalama-gcs-cloudml\n",
    "\n",
    "MODEL_NAME=\"babyweight_estimator\"\n",
    "\n",
    "PACKAGE_PATH=packages/babyweight-tf1.4/trainer\n",
    "TRAIN_FILES=gs://${BUCKET}/data/babyweight/big_data/train-*.csv\n",
    "VALID_FILES=gs://${BUCKET}/data/babyweight/big_data/eval-*.csv\n",
    "MODEL_DIR=gs://${BUCKET}/models/babyweight/${MODEL_NAME}_${TIER}\n",
    "\n",
    "CURRENT_DATE=`date +%Y%m%d_%H%M%S`\n",
    "JOB_NAME=train_${MODEL_NAME}_${TIER}_${CURRENT_DATE}\n",
    "\n",
    "gcloud ml-engine jobs submit training ${JOB_NAME} \\\n",
    "        --job-dir=${MODEL_DIR} \\\n",
    "        --runtime-version=1.4 \\\n",
    "        --region=${REGION} \\\n",
    "        --module-name=trainer.task \\\n",
    "        --package-path=${PACKAGE_PATH} \\\n",
    "        --config=ml-packages/babyweight-tf1.4/custom.yaml \\\n",
    "        -- \\\n",
    "        --train-files=${TRAIN_FILES} \\\n",
    "        --num-epochs=100 \\\n",
    "        --train-batch-size=1000 \\\n",
    "        --eval-files=${VALID_FILES} \\\n",
    "        --eval-batch-size=1000 \\\n",
    "        --learning-rate=0.001 \\\n",
    "        --hidden-units=\"64,0,0\" \\\n",
    "        --layer-sizes-scale-factor=0.5 \\\n",
    "        --num-layers=3 \\\n",
    "        --job-dir=${MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters Tuning on Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Submitting a Cloud ML Engine job...\"\n",
    "\n",
    "REGION=europe-west1\n",
    "BUCKET=ksalama-gcs-cloudml\n",
    "\n",
    "MODEL_NAME=\"babyweight_estimator\"\n",
    "\n",
    "PACKAGE_PATH=packages/babyweight-tf1.4/trainer\n",
    "TRAIN_FILES=gs://${BUCKET}/data/babyweight/big_data/train-*.csv\n",
    "VALID_FILES=gs://${BUCKET}/data/babyweight/big_data/eval-*.csv\n",
    "MODEL_DIR=gs://${BUCKET}/models/babyweight/${MODEL_NAME}_tune\n",
    "\n",
    "CURRENT_DATE=`date +%Y%m%d_%H%M%S`\n",
    "JOB_NAME=tune_${MODEL_NAME}_${TIER}_${CURRENT_DATE}\n",
    "\n",
    "gcloud ml-engine jobs submit training ${JOB_NAME} \\\n",
    "        --job-dir=${MODEL_DIR} \\\n",
    "        --runtime-version=1.4 \\\n",
    "        --region=${REGION} \\\n",
    "        --module-name=trainer.task \\\n",
    "        --package-path=${PACKAGE_PATH} \\\n",
    "        --config=ml-packages/babyweight-tf1.4/hyperparams.yaml \\\n",
    "        -- \\\n",
    "        --train-files=${TRAIN_FILES} \\\n",
    "        --num-epochs=100 \\\n",
    "        --train-batch-size=1000 \\\n",
    "        --eval-files=${VALID_FILES} \\\n",
    "        --eval-batch-size=1000 \\\n",
    "        --job-dir=${MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deploy the Model on Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "REGION=europe-west1\n",
    "BUCKET=ksalama-gcs-cloudml\n",
    "\n",
    "MODEL_NAME=\"babyweight_estimator\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "\n",
    "MODEL_BINARIES=$(gsutil ls gs://${BUCKET}/models/babyweight/${MODEL_NAME}/export/estimate | tail -1)\n",
    "\n",
    "gsutil ls ${MODEL_BINARIES}\n",
    "\n",
    "# #delete model version\n",
    "# gcloud ml-engine versions delete ${MODEL_VERSION} --model=${MODEL_NAME}\n",
    "\n",
    "# #delete model\n",
    "# gcloud ml-engine models delete ${MODEL_NAME}\n",
    "\n",
    "# #deploy model to GCP\n",
    "# gcloud ml-engine models create ${MODEL_NAME} --regions=${REGION}\n",
    "\n",
    "# #deploy model version\n",
    "# gcloud ml-engine versions create ${MODEL_VERSION} --model=${MODEL_NAME} --origin=${MODEL_BINARIES} --runtime-version=1.4\n",
    "\n",
    "# echo  ${MODEL_NAME} ${MODEL_VERSION} \n",
    "# #invoke deployed model to make prediction given new data instances\n",
    "# gcloud ml-engine predict --model=${MODEL_NAME} --version=${MODEL_VERSION} --json-instances=data/babyweight/new-data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Consume the Depoyed Model as API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "def estimate(project, model_name, version, instances):\n",
    "\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "    api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "                discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "    request_data = {'instances': instances}\n",
    "\n",
    "    model_url = 'projects/{}/models/{}/versions/{}'.format(project, model_name, version)\n",
    "    response = api.projects().predict(body=request_data, name=model_url).execute()\n",
    "\n",
    "    estimates = list(map(lambda item: round(item[\"scores\"],2)\n",
    "        ,response[\"predictions\"]\n",
    "    ))\n",
    "\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT='ksalama-gcp-playground'\n",
    "MODEL_NAME='babyweight_estimator'\n",
    "VERSION='v1'\n",
    "\n",
    "instances = [\n",
    "      {\n",
    "        'is_male': 'True',\n",
    "        'mother_age': 26.0,\n",
    "        'mother_race': 'Asian Indian',\n",
    "        'plurality': 1.0,\n",
    "        'gestation_weeks': 39,\n",
    "        'mother_married': 'True',\n",
    "        'cigarette_use': 'False',\n",
    "        'alcohol_use': 'False'\n",
    "      },\n",
    "      {\n",
    "        'is_male': 'False',\n",
    "        'mother_age': 29.0,\n",
    "        'mother_race': 'Asian Indian',\n",
    "        'plurality': 1.0,\n",
    "        'gestation_weeks': 38,\n",
    "        'mother_married': 'True',\n",
    "        'cigarette_use': 'False',\n",
    "        'alcohol_use': 'False'\n",
    "      },\n",
    "      {\n",
    "        'is_male': 'True',\n",
    "        'mother_age': 26.0,\n",
    "        'mother_race': 'White',\n",
    "        'plurality': 1.0,\n",
    "        'gestation_weeks': 39,\n",
    "        'mother_married': 'True',\n",
    "        'cigarette_use': 'False',\n",
    "        'alcohol_use': 'False'\n",
    "      },\n",
    "      {\n",
    "        'is_male': 'True',\n",
    "        'mother_age': 26.0,\n",
    "        'mother_race': 'White',\n",
    "        'plurality': 2.0,\n",
    "        'gestation_weeks': 37,\n",
    "        'mother_married': 'True',\n",
    "        'cigarette_use': 'False',\n",
    "        'alcohol_use': 'True'\n",
    "      }\n",
    "  ]\n",
    "\n",
    "estimates = estimate(instances=instances\n",
    "                     ,project=PROJECT\n",
    "                     ,model_name=MODEL_NAME\n",
    "                     ,version=VERSION)\n",
    "\n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
