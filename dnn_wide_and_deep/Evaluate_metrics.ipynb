{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluate metrics from the classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                                                                                                                                                     \n",
    "from tensorflow import data\n",
    "import tensorflow_transform as tft \n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform.coders as tft_coders\n",
    "\n",
    "from tensorflow_transform.beam import impl\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "from tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n",
    "\n",
    "from tensorflow_transform.tf_metadata import metadata_io\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.saved import saved_transform_io\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "import argparse\n",
    "\n",
    "import apache_beam as beam\n",
    "\n",
    "import os\n",
    "import params\n",
    "import shutil\n",
    "import dnn_estimator\n",
    "import input\n",
    "import metadata\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "TRAIN_SIZE = metadata.TRAIN_SIZE\n",
    "NUM_EPOCHS = metadata.NUM_EPOCHS\n",
    "BATCH_SIZE = metadata.BATCH_SIZE\n",
    "TOTAL_STEPS = (TRAIN_SIZE/BATCH_SIZE)*NUM_EPOCHS\n",
    "EVAL_EVERY_SEC = metadata.EVAL_EVERY_SEC\n",
    "\n",
    "\n",
    "## set the run id for the analysis run\n",
    "run_id = \"16\"\n",
    "\n",
    "MODEL_NAME = 'dnn_estimator' \n",
    "model_dir = os.path.join(params.Params.MODELS_DIR, MODEL_NAME)\n",
    "model_dir = os.path.join(model_dir, run_id)\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    tf_random_seed=19830610,\n",
    "    log_step_count_steps=1000,\n",
    "    save_checkpoints_secs=EVAL_EVERY_SEC,\n",
    "    keep_checkpoint_max=3,\n",
    "    model_dir=model_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata.hparams)\n",
    "print(\"\")\n",
    "print(\"Model Directory:\", run_config.model_dir)\n",
    "print(\"Dataset Size:\", TRAIN_SIZE)\n",
    "print(\"Batch Size:\", BATCH_SIZE)\n",
    "print(\"Steps per Epoch:\",TRAIN_SIZE/BATCH_SIZE)\n",
    "print(\"Total Steps:\", TOTAL_STEPS)\n",
    "\n",
    "\n",
    "VALID_SIZE = 10223\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = dnn_estimator.create_estimator(run_config, metadata.hparams)\n",
    "\n",
    "train_metrics = estimator.evaluate(\n",
    "    input_fn = input.generate_tfrecords_input_fn(\n",
    "        files_name_pattern= params.Params.TRANSFORMED_TRAIN_DATA_FILE_PREFIX+\"*\",\n",
    "        mode= tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size= TRAIN_SIZE),\n",
    "    steps=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Train Measures: {}\".format(train_metrics))\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "eval_metrics = estimator.evaluate(\n",
    "    input_fn=input.generate_tfrecords_input_fn(\n",
    "        files_name_pattern= params.Params.TRANSFORMED_EVAL_DATA_FILE_PREFIX+\"*\",\n",
    "        mode= tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size= VALID_SIZE),\n",
    "    steps=1\n",
    ")\n",
    "print(\"\")\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Valid Measures: {}\".format(eval_metrics))\n",
    "print(\"############################################################################################\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics['auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validation Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics['auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Re-run using different parameters</h2>\n",
    "<h2>dropout_prob=0.2</2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## set the run id for the analysis run\n",
    "run_id = \"15\"\n",
    "\n",
    "MODEL_NAME = 'dnn_estimator' \n",
    "model_dir = os.path.join(params.Params.MODELS_DIR, MODEL_NAME)\n",
    "model_dir = os.path.join(model_dir, run_id)\n",
    "\n",
    "#\n",
    "# metadata.hparams.dropout_prob = 0.2\n",
    "#`\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    tf_random_seed=19830610,\n",
    "    log_step_count_steps=1000,\n",
    "    save_checkpoints_secs=EVAL_EVERY_SEC,\n",
    "    keep_checkpoint_max=3,\n",
    "    model_dir=model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata.hparams)\n",
    "print(\"\")\n",
    "print(\"Model Directory:\", run_config.model_dir)\n",
    "print(\"Dataset Size:\", TRAIN_SIZE)\n",
    "print(\"Batch Size:\", BATCH_SIZE)\n",
    "print(\"Steps per Epoch:\",TRAIN_SIZE/BATCH_SIZE)\n",
    "print(\"Total Steps:\", TOTAL_STEPS)\n",
    "\n",
    "\n",
    "VALID_SIZE = 10223\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = dnn_estimator.create_estimator(run_config, metadata.hparams)\n",
    "\n",
    "train_metrics = estimator.evaluate(\n",
    "    input_fn = input.generate_tfrecords_input_fn(\n",
    "        files_name_pattern= params.Params.TRANSFORMED_TRAIN_DATA_FILE_PREFIX+\"*\",\n",
    "        mode= tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size= TRAIN_SIZE),\n",
    "    steps=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Train Measures: {}\".format(train_metrics))\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "eval_metrics = estimator.evaluate(\n",
    "    input_fn=input.generate_tfrecords_input_fn(\n",
    "        files_name_pattern= params.Params.TRANSFORMED_EVAL_DATA_FILE_PREFIX+\"*\",\n",
    "        mode= tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size= VALID_SIZE),\n",
    "    steps=1\n",
    ")\n",
    "print(\"\")\n",
    "print(\"############################################################################################\")\n",
    "print(\"# Valid Measures: {}\".format(eval_metrics))\n",
    "print(\"############################################################################################\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics['auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validation results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
