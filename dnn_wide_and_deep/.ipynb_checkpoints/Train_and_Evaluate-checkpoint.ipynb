{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train and evaluate data set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "import tensorflow_transform as tft \n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform.coders as tft_coders\n",
    "\n",
    "from tensorflow_transform.beam import impl\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "from tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n",
    "\n",
    "from tensorflow_transform.tf_metadata import metadata_io\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.saved import saved_transform_io\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "import argparse\n",
    "\n",
    "import apache_beam as beam\n",
    "\n",
    "import os\n",
    "import params\n",
    "import shutil\n",
    "import dnn_estimator\n",
    "import featurizer\n",
    "import metadata\n",
    "import input\n",
    "from datetime import datetime\n",
    "\n",
    "TRAIN_SIZE = metadata.TRAIN_SIZE\n",
    "NUM_EPOCHS = metadata.NUM_EPOCHS\n",
    "BATCH_SIZE = metadata.BATCH_SIZE\n",
    "TOTAL_STEPS = (TRAIN_SIZE/BATCH_SIZE)*NUM_EPOCHS\n",
    "EVAL_EVERY_SEC = metadata.EVAL_EVERY_SEC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Serving function for exporter in JSON format</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_serving_fn():\n",
    "\n",
    "    # get the feature_spec of raw data\n",
    "    raw_metadata = featurizer.create_raw_metadata()\n",
    "    raw_placeholder_spec = raw_metadata.schema.as_batched_placeholders()\n",
    "    raw_placeholder_spec.pop(metadata.TARGET_FEATURE_NAME)\n",
    "\n",
    "    def _serving_fn():\n",
    "\n",
    "        raw_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(raw_placeholder_spec)\n",
    "        raw_features, recevier_tensors, _ = raw_input_fn()\n",
    "\n",
    "        # apply tranform_fn on raw features\n",
    "        _, transformed_features = (\n",
    "            saved_transform_io.partially_apply_saved_transform(\n",
    "                os.path.join(params.Params.TRANSFORM_ARTEFACTS_DIR, transform_fn_io.TRANSFORM_FN_DIR),\n",
    "            raw_features)\n",
    "        )\n",
    "\n",
    "        # apply the process_features function to transformed features\n",
    "        transformed_features = input.process_features(transformed_features)\n",
    "\n",
    "        return tf.estimator.export.ServingInputReceiver(\n",
    "            transformed_features, raw_features)\n",
    "\n",
    "    return _serving_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Evaluation spec</h2>\n",
    "<h3>Includes the input function, Training/Eval mode, num_epocs, batch size, and max_steps</h3>\n",
    "<h3>Set the path to the <b>transformed</b> input files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input.generate_tfrecords_input_fn(\n",
    "        params.Params.TRANSFORMED_TRAIN_DATA_FILE_PREFIX+\"*\",\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "        num_epochs=metadata.hparams.num_epochs,\n",
    "        batch_size=metadata.hparams.batch_size\n",
    "    ),  \n",
    "    max_steps=metadata.hparams.max_steps,\n",
    "    hooks=None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = input.generate_tfrecords_input_fn(\n",
    "        params.Params.TRANSFORMED_EVAL_DATA_FILE_PREFIX+\"*\",\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        num_epochs=1,\n",
    "        batch_size=metadata.hparams.batch_size\n",
    "    ),  \n",
    "    exporters=[tf.estimator.LatestExporter(\n",
    "        name=\"estimate\", # the name of the folder in which the model will be exported to under export\n",
    "        serving_input_receiver_fn=generate_json_serving_fn(),\n",
    "        exports_to_keep=1,\n",
    "        as_text=False)],\n",
    "    steps=None,\n",
    "    throttle_secs=EVAL_EVERY_SEC\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run the training job</h2>\n",
    "<h3>Create the estimator and run train and evaluate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.Params.TRAIN:\n",
    "    if not params.Params.RESUME_TRAINING:\n",
    "        print(\"Removing previous training artefacts...\")\n",
    "        shutil.rmtree(model_dir, ignore_errors=True)\n",
    "    else:\n",
    "        print(\"Resuming training...\")\n",
    "\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    time_start = datetime.utcnow()\n",
    "    print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "    print(\".......................................\")\n",
    "\n",
    "    estimator = dnn_estimator.create_estimator(run_config, metadata.hparams)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec,\n",
    "        eval_spec=eval_spec\n",
    "    )\n",
    "\n",
    "    time_end = datetime.utcnow()\n",
    "    print(\".......................................\")\n",
    "    print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "    print(\"\")\n",
    "    time_elapsed = time_end - time_start\n",
    "    print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))\n",
    "else:\n",
    "    print \"Training was skipped!\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
